{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "42e60f26-bb00-49cb-967f-816543eec3d7",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import StringIndexer\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "from pyspark.mllib.evaluation import MulticlassMetrics\n",
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "from pyspark.sql.types import DoubleType\n",
    "from pyspark.sql.types import IntegerType\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.sql.functions import when\n",
    "from pyspark.sql.functions import col"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data and create dateframe. Fraction can control the proportion of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a0573459-eb78-48f0-8b9d-b334dcca7b29",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName(\"RandomSample\").getOrCreate()\n",
    "\n",
    "#The file is in Google Cloud Platform's bucket\n",
    "file_path = \"gs://data_rz/full_data_flightdelay.csv\"  \n",
    "df = spark.read.csv(file_path, header=True, inferSchema=True)\n",
    "\n",
    "#fraction controls the percentage of data used. In this project, we used 25%, 50% and 100%\n",
    "fraction = 1.0\n",
    "random_sample = df.sample(fraction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transform categorical columns into numeric columns. DEP_TIME_BLK means time period such as 0000-0059. CARRIER_NAME is the airline of this flight. DEPARTING_AIRPORT and PREVIOUS_AIRPORT is the departure and landing airports.  \n",
    "Then we drop the initial columns.  \n",
    "The next step is change the type of some columns bacause only specified type can be used in tree model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "787dc8d4-0aeb-4fcf-ad07-dcf019dc2f36",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Transfer categorical to numerical\n",
    "columns_to_index = [\"DEP_TIME_BLK\", \"CARRIER_NAME\", \"DEPARTING_AIRPORT\", \"PREVIOUS_AIRPORT\"]\n",
    "indexers = [StringIndexer(inputCol=col, outputCol=f\"{col}_index\", handleInvalid=\"keep\") for col in columns_to_index]\n",
    "pipeline = Pipeline(stages=indexers)\n",
    "indexed_df = pipeline.fit(random_sample).transform(random_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "29b4e0b5-6f48-4bcc-89db-26e81785d08f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Data transfer\n",
    "columns_to_drop = ['DEP_TIME_BLK', 'CARRIER_NAME', 'DEPARTING_AIRPORT', 'PREVIOUS_AIRPORT', 'label']\n",
    "indexed_df = indexed_df.drop(*columns_to_drop)\n",
    "indexed_df = indexed_df.withColumn(\"DEP_DEL15\", indexed_df[\"DEP_DEL15\"].cast(DoubleType()))\n",
    "indexed_df = indexed_df.withColumn(\"PREVIOUS_AIRPORT_index\", indexed_df[\"PREVIOUS_AIRPORT_index\"].cast(IntegerType()))\n",
    "indexed_df = indexed_df.withColumn(\"DEPARTING_AIRPORT_index\", indexed_df[\"DEPARTING_AIRPORT_index\"].cast(IntegerType()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the size of airplane by the number of seats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "41cb3f7c-b53a-495e-85e0-ca32beff52ee",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Change NUMBER_OF_SEATS column to numerical\n",
    "condition_0 = indexed_df['NUMBER_OF_SEATS'] < 150\n",
    "condition_1 = (indexed_df['NUMBER_OF_SEATS'] >= 150) & (indexed_df['NUMBER_OF_SEATS'] <= 300)\n",
    "condition_2 = indexed_df['NUMBER_OF_SEATS'] > 300\n",
    "\n",
    "indexed_df = indexed_df.withColumn('SEATS_CATEGORY',\n",
    "                                   when(condition_0, 0)\n",
    "                                   .when(condition_1, 1)\n",
    "                                   .when(condition_2, 2)\n",
    "                                   .otherwise(None)) \n",
    "\n",
    "indexed_df = indexed_df.drop('NUMBER_OF_SEATS')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the data. Use grid search to tune the parameter. Number of K-folds is 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d800338c-ba81-4267-b95f-6e14872ae7b5",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best RegParam: 0.01\n",
      "Best ElasticNetParam: 0.0\n",
      "Best MaxIter: 100\n"
     ]
    }
   ],
   "source": [
    "#Train using grid search\n",
    "feature_columns = [col for col in indexed_df.columns if col != 'DEP_DEL15']\n",
    "\n",
    "vector_assembler = VectorAssembler(inputCols=feature_columns, outputCol=\"features\")\n",
    "\n",
    "lr_classifier = LogisticRegression(labelCol=\"DEP_DEL15\", featuresCol=\"features\")\n",
    "\n",
    "pipeline = Pipeline(stages=[vector_assembler, lr_classifier])\n",
    "\n",
    "param_grid = (ParamGridBuilder()\n",
    "              .addGrid(lr_classifier.regParam, [0.01, 0.1, 1.0])\n",
    "              .addGrid(lr_classifier.elasticNetParam, [0.0, 0.5, 1.0])\n",
    "              .addGrid(lr_classifier.maxIter, [10, 50, 100])\n",
    "              .build())\n",
    "\n",
    "#Save into cache for quickily running\n",
    "cached_df = indexed_df.cache()\n",
    "\n",
    "crossval = CrossValidator(estimator=pipeline,\n",
    "                          estimatorParamMaps=param_grid,\n",
    "                          evaluator=BinaryClassificationEvaluator(labelCol=\"DEP_DEL15\", metricName=\"areaUnderROC\"),\n",
    "                          numFolds=2)\n",
    "\n",
    "cv_model = crossval.fit(cached_df)\n",
    "\n",
    "best_model = cv_model.bestModel\n",
    "\n",
    "print(\"Best RegParam:\", best_model.stages[-1]._java_obj.getRegParam())\n",
    "print(\"Best ElasticNetParam:\", best_model.stages[-1]._java_obj.getElasticNetParam())\n",
    "print(\"Best MaxIter:\", best_model.stages[-1]._java_obj.getMaxIter())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate the model by some metrics. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "90ba79d2-261d-4c62-8457-a875c1104fc0",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC: 0.6338357960219884\n",
      "Accuracy: 0.8089738776555481\n",
      "Precision: 0.7541789329521513\n",
      "Recall: 0.8089738776555482\n",
      "F1-Score: 0.7278706651805659\n"
     ]
    }
   ],
   "source": [
    "#Make prediction\n",
    "predictions = cv_model.transform(indexed_df)\n",
    "\n",
    "predictions = cv_model.transform(indexed_df)\n",
    "\n",
    "evaluator_roc = BinaryClassificationEvaluator(labelCol=\"DEP_DEL15\", metricName=\"areaUnderROC\")\n",
    "roc = evaluator_roc.evaluate(predictions)\n",
    "\n",
    "evaluator_multi = MulticlassClassificationEvaluator(labelCol=\"DEP_DEL15\", metricName=\"accuracy\")\n",
    "accuracy = evaluator_multi.evaluate(predictions)\n",
    "\n",
    "evaluator_precision = MulticlassClassificationEvaluator(labelCol=\"DEP_DEL15\", metricName=\"weightedPrecision\")\n",
    "precision = evaluator_precision.evaluate(predictions)\n",
    "\n",
    "evaluator_recall = MulticlassClassificationEvaluator(labelCol=\"DEP_DEL15\", metricName=\"weightedRecall\")\n",
    "recall = evaluator_recall.evaluate(predictions)\n",
    "\n",
    "evaluator_f1 = MulticlassClassificationEvaluator(labelCol=\"DEP_DEL15\", metricName=\"f1\")\n",
    "f1_score = evaluator_f1.evaluate(predictions)\n",
    "\n",
    "print(\"ROC:\", roc)  \n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1-Score:\", f1_score)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "BIA-678 Project-Random forest",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

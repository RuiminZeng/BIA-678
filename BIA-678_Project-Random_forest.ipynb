{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "42e60f26-bb00-49cb-967f-816543eec3d7",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import StringIndexer\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "from pyspark.mllib.evaluation import MulticlassMetrics\n",
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "from pyspark.sql.types import DoubleType\n",
    "from pyspark.sql.types import IntegerType\n",
    "from pyspark.sql.functions import when\n",
    "from pyspark.sql.functions import col"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data and create dateframe. Fraction can control the proportion of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a0573459-eb78-48f0-8b9d-b334dcca7b29",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName(\"RandomSample\").getOrCreate()\n",
    "\n",
    "#The file is in Google Cloud Platform's bucket\n",
    "file_path = \"gs://data_rz/full_data_flightdelay.csv\"  \n",
    "df = spark.read.csv(file_path, header=True, inferSchema=True)\n",
    "\n",
    "#fraction controls the percentage of data used. In this project, we used 25%, 50% and 100%\n",
    "fraction = 1.0\n",
    "random_sample = df.sample(fraction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transform categorical columns into numeric columns. DEP_TIME_BLK means time period such as 0000-0059. CARRIER_NAME is the airline of this flight. DEPARTING_AIRPORT and PREVIOUS_AIRPORT is the departure and landing airports.  \n",
    "Then we drop the initial columns.  \n",
    "The next step is change the type of some columns bacause only specified type can be used in tree model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "787dc8d4-0aeb-4fcf-ad07-dcf019dc2f36",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Transfer categorical to numerical\n",
    "columns_to_index = [\"DEP_TIME_BLK\", \"CARRIER_NAME\", \"DEPARTING_AIRPORT\", \"PREVIOUS_AIRPORT\"]\n",
    "indexers = [StringIndexer(inputCol=col, outputCol=f\"{col}_index\", handleInvalid=\"keep\") for col in columns_to_index]\n",
    "pipeline = Pipeline(stages=indexers)\n",
    "indexed_df = pipeline.fit(random_sample).transform(random_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "29b4e0b5-6f48-4bcc-89db-26e81785d08f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Data transfer\n",
    "columns_to_drop = ['DEP_TIME_BLK', 'CARRIER_NAME', 'DEPARTING_AIRPORT', 'PREVIOUS_AIRPORT', 'label']\n",
    "indexed_df = indexed_df.drop(*columns_to_drop)\n",
    "indexed_df = indexed_df.withColumn(\"DEP_DEL15\", indexed_df[\"DEP_DEL15\"].cast(DoubleType()))\n",
    "indexed_df = indexed_df.withColumn(\"PREVIOUS_AIRPORT_index\", indexed_df[\"PREVIOUS_AIRPORT_index\"].cast(IntegerType()))\n",
    "indexed_df = indexed_df.withColumn(\"DEPARTING_AIRPORT_index\", indexed_df[\"DEPARTING_AIRPORT_index\"].cast(IntegerType()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the size of airplane by the number of seats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "41cb3f7c-b53a-495e-85e0-ca32beff52ee",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Change NUMBER_OF_SEATS column to numerical\n",
    "condition_0 = indexed_df['NUMBER_OF_SEATS'] < 150\n",
    "condition_1 = (indexed_df['NUMBER_OF_SEATS'] >= 150) & (indexed_df['NUMBER_OF_SEATS'] <= 300)\n",
    "condition_2 = indexed_df['NUMBER_OF_SEATS'] > 300\n",
    "\n",
    "indexed_df = indexed_df.withColumn('SEATS_CATEGORY',\n",
    "                                   when(condition_0, 0)\n",
    "                                   .when(condition_1, 1)\n",
    "                                   .when(condition_2, 2)\n",
    "                                   .otherwise(None)) \n",
    "\n",
    "indexed_df = indexed_df.drop('NUMBER_OF_SEATS')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the data. Use grid search to tune the parameter. Number of K-folds is 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2b5fee3a-a075-4389-8ea3-c18c1caaafdd",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Num Trees: 100\n",
      "Best Max Depth: 10\n"
     ]
    }
   ],
   "source": [
    "#Train using grid search\n",
    "feature_columns = [col for col in indexed_df.columns if col != 'DEP_DEL15']\n",
    "vector_assembler = VectorAssembler(inputCols=feature_columns, outputCol=\"features\")\n",
    "\n",
    "rf_classifier = RandomForestClassifier(labelCol=\"DEP_DEL15\", featuresCol=\"features\")\n",
    "\n",
    "pipeline = Pipeline(stages=[vector_assembler, rf_classifier])\n",
    "\n",
    "param_grid = (ParamGridBuilder()\n",
    "              .addGrid(rf_classifier.numTrees, [10, 50, 100])\n",
    "              .addGrid(rf_classifier.maxDepth, [1, 5, 10])\n",
    "              .addGrid(rf_classifier.subsamplingRate, [0.8, 1.0])\n",
    "              .addGrid(rf_classifier.minInstancesPerNode, [1, 5, 10])                \n",
    "              .build())\n",
    "\n",
    "#Save into cache for quickily running\n",
    "cached_df = indexed_df.cache()\n",
    "\n",
    "crossval = CrossValidator(estimator=pipeline,\n",
    "                          estimatorParamMaps=param_grid,\n",
    "                          evaluator=BinaryClassificationEvaluator(labelCol=\"DEP_DEL15\", metricName=\"areaUnderROC\"),\n",
    "                          numFolds=2) \n",
    "\n",
    "cv_model = crossval.fit(indexed_df)\n",
    "\n",
    "best_model = cv_model.bestModel\n",
    "\n",
    "print(\"Best Num Trees:\", best_model.stages[-1]._java_obj.getNumTrees())\n",
    "print(\"Best Max Depth:\", best_model.stages[-1]._java_obj.getMaxDepth())\n",
    "print(\"Best SubsamplingRate:\", best_model.stages[-1]._java_obj.getSubsamplingRate())\n",
    "print(\"Best MinInstancesPerNode:\", best_model.stages[-1]._java_obj.getMinInstancesPerNode())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate the model by some metrics. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f7c2a2e2-3780-4719-9743-f4a84b9f8d4e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Area under ROC: 0.6441241431688508\n",
      "Accuracy: 0.8032510351173133\n",
      "Precision: 0.771872300700962\n",
      "Recall: 0.8032510351173133\n",
      "F1-Score: 0.7176598621323539\n"
     ]
    }
   ],
   "source": [
    "#Make prediction\n",
    "predictions = cv_model.transform(indexed_df)\n",
    "\n",
    "evaluator_roc = BinaryClassificationEvaluator(labelCol=\"DEP_DEL15\", metricName=\"areaUnderROC\")\n",
    "roc = evaluator_roc.evaluate(predictions)\n",
    "print(\"Area under ROC:\", roc)\n",
    "\n",
    "evaluator_multi = MulticlassClassificationEvaluator(labelCol=\"DEP_DEL15\", metricName=\"accuracy\")\n",
    "accuracy = evaluator_multi.evaluate(predictions)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "precision = evaluator_multi.evaluate(predictions, {evaluator_multi.metricName: \"weightedPrecision\"})\n",
    "print(\"Precision:\", precision)\n",
    "\n",
    "recall = evaluator_multi.evaluate(predictions, {evaluator_multi.metricName: \"weightedRecall\"})\n",
    "print(\"Recall:\", recall)\n",
    "\n",
    "f1_score = evaluator_multi.evaluate(predictions, {evaluator_multi.metricName: \"f1\"})\n",
    "print(\"F1-Score:\", f1_score)\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "BIA-678 Project-Random forest",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
